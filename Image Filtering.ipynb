{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Filtering\n",
    "---\n",
    "|TABLE|OF|CONTENT|||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "|---|||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "[Introduction](#intro)\n",
    "[Convolution](#conv)\n",
    "[Sharpen](#sharpen)\n",
    "[Blur](#blur)\n",
    "[Emboss](#emboss)\n",
    "[Motion Blur](#motion_blur)\n",
    "[Find Edges](#edge_detect)\n",
    "[Sepia](#sepia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='intro'></div>\n",
    "\n",
    "### Introduction\n",
    "---\n",
    "- *Image filtering allows us to apply various effects on photos.*\n",
    "- *The type of image filtering described here uses a 2D filter similar to the one included in Paint Shop*\n",
    "*Pro as User Defined Filter and in Photoshop as Custom Filter.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='conv'></div>\n",
    "\n",
    "### Convolution\n",
    "---\n",
    "- *The trick of image filtering is that you have a 2D filter matrix, and the 2D image.*\n",
    "- *Then, for every pixel of the image, take the sum of products. Each product is the color value of the current pixel or a neighbor of it, with the corresponding value of the filter matrix.*\n",
    "- *The center of the filter matrix( **anchor of the filter** ) has to be multiplied with the current pixel, the other elements of the filter matrix with corresponding neighbor pixels.*\n",
    "\n",
    "#### *Rules about the filters:*\n",
    "- Size is preferred to be of odd dimension so it's centered and padding can done in case of same convolution ($padding = \\frac{f-1}{2}$ for same convolution).\n",
    "- Sum of the elements of the filter is preferred to be one for output image to be of same brightness as input image.\n",
    "- If the sum of the elements is larger than 1, the result will be a brighter image, and if it's smaller than 1, a darker image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import scipy\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(image):\n",
    "    window_name='scenery'\n",
    "    # print(image.shape) (400,400,3)\n",
    "    cv2.namedWindow(window_name,cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(window_name,image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write(text,image):\n",
    "    cv2.imwrite(text+\".jpeg\",image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Image  \n",
    "---\n",
    "![Scenery](images/scenery.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r'scenery.jpeg'\n",
    "image=cv2.imread(path)\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply(image,kernel):\n",
    "    _,f=kernel.shape\n",
    "    p=int((f-1)//2)\n",
    "    image=np.pad(image,((p,p),(p,p),(0,0)))\n",
    "    nh,nw,nc=image.shape\n",
    "    result=np.zeros((nh-f+1,nw-f+1,nc))\n",
    "    for c in range(nc):\n",
    "        for w in range(nw):\n",
    "            for h in range(nh):\n",
    "                if h+f-1>=nh or w+f-1>=nw:\n",
    "                    break\n",
    "                result[h][w][c]=min(max(int(np.sum(np.multiply(image[h:h+f,w:w+f,c],kernel))),0),255)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='sharpen'></div>\n",
    "\n",
    "# Sharpen Image\n",
    "---\n",
    "![Sharpen](images/sharpen.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpen(img):\n",
    "    image=copy.deepcopy(img)\n",
    "    kernel=np.array([[-1,-1,-1],[-1,9,-1],[-1,-1,-1]])\n",
    "#     return apply(image,kernel)\n",
    "    return cv2.filter2D(image,-1,kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='blur'></div>\n",
    "\n",
    "# Blur Image\n",
    "---\n",
    "* Blurring is done for example by taking the average of the current pixel and its 4 neighbors. \n",
    "* Take the sum of the current pixel and its 4 neighbors, and divide it through 5, or thus fill in 5 times the value 0.2 in the filter:\n",
    "\n",
    "![Blur](images/blur.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur(img):\n",
    "    image=copy.deepcopy(img)\n",
    "    kernel=np.array([[0.0,0.2,0.0],[0.2,0.2,0.2],[0.0,0.2,0.0]])\n",
    "    return cv2.filter2D(image,-1,kernel)\n",
    "#     return apply(image,kernel)\n",
    "display(blur(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='emboss'></div>\n",
    "\n",
    "# Emboss Image\n",
    "---\n",
    "- An emboss filter gives a 3D shadow effect to the image, the result is very useful for a bumpmap of the image. \n",
    "- It can be achieved by taking a pixel on one side of the center, and subtracting one of the other side from it.\n",
    "- Pixels can get either a positive or a negative result. \n",
    "- To use the negative pixels as shadow and positive ones as light, for a bumpmap, a bias of 128 is added to the image. \n",
    "- Now, most parts of the image will be gray, and the sides will be either dark gray/black or bright gray/white.\n",
    "\n",
    "For example here's an emboss filter with an angle of 45Â°:\n",
    "\n",
    "![Emboss](images/emboss.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emboss(img):\n",
    "    image=copy.deepcopy(img)\n",
    "    kernel=np.array([[-1,-1,0],[-1,0,1],[0,1,1]])\n",
    "    return cv2.filter2D(image,-1,kernel)\n",
    "#     return apply(image,kernel)\n",
    "display(emboss(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='motion_blur'></div>\n",
    "\n",
    "# Motion Blur Image\n",
    "- Motion blur is achieved by blurring in only 1 direction\n",
    "- It's as if the camera is moving from the top left to the bottom right, hence the name.\n",
    "\n",
    "![Motion Blur](images/motion_blur.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motion_blur(img):\n",
    "    image=copy.deepcopy(img)\n",
    "    kernel=(1/9)*np.eye(9)\n",
    "    return cv2.filter2D(image,-1,kernel)\n",
    "display(motion_blur(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='edge_detect'></div>\n",
    "\n",
    "# Edges Detection Image\n",
    "---\n",
    "- A filter to find the diagonal edges looks like this:\n",
    "![edges_detection](images/edges_detection.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edges_detection(img):\n",
    "    image=copy.deepcopy(img)\n",
    "    kernel=np.array([\n",
    "        [-1,  0, 0,  0,  0],\n",
    "        [0,  -2, 0,  0,  0],\n",
    "        [0,  0,  6,  0,  0],\n",
    "        [0,  0,  0,  -2,  0],\n",
    "        [0,  0,  0,  0,  -1]])\n",
    "    return cv2.filter2D(image,-1,kernel)\n",
    "display(edges_detection(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='sepia'></div>\n",
    "\n",
    "### Sepia Image\n",
    "---\n",
    "- The sepia effect is a well-known tonal editing technique that adds a warmer tone that gives an image a vintage or archival quality. \n",
    "- If you want to add a bit of style to your composition, the sepia effect works exceptionally well with black and white images.\n",
    "![sepia](images/sepia.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sepia(img):\n",
    "    image=copy.deepcopy(img)\n",
    "#     kernel=np.random.rand(3,3)\n",
    "#     Following is a special sepia matrix used often.\n",
    "    kernel = np.array([[0.272, 0.534, 0.131],\n",
    "                       [0.349, 0.686, 0.168],\n",
    "                       [0.393, 0.769, 0.189]])\n",
    "    return cv2.filter2D(image, -1, kernel)\n",
    "display(sepia(image))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
